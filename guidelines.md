---
layout: default
title: Participation Guidelines
has_children: true
nav_order: 2
---

# Participation Guidelines

## Who can participate

Participation is open to **all NLP practitioners worldwide**: students, researchers, and industrial teams. You can join as an individual or as a team.

**Important:** At least one author of each accepted paper must register for the EVALITA conference in Bari (with a workshop fee) and present their work during the ATE-IT workshop.

## How to register
Please send an email to **ateit@gmail.com** with the following information:
- Group name and acronym
-	Participants’ full names and affiliations
-	Contact email address(es)
-	Subtask(s) you wish to participate in

## What participants should do
The shared task is divided into four consecutive phases.
- **Phase 1: Development (22 September – 2 November)** Training and development data is released on the Datasets page. Teams will design, implement, and test their system(s) for one or both subtasks using the provided data.
- **Phase 2: Evaluation (3 – 17 November)** Test data is released on the Datasets page. Teams must generate predictions and submit results according to the required format. Together with the results, participants must submit a link to the source code repository on GitHub.
- **Phase 3: Reporting (18 November – 15 December)** Teams must write and submit a short technical report according to the provided format. The report must describe the proposed system(s). It should outline:
  -	System architecture and methods
  -	Resources and pretrained models used
  -	Results and error analysis
- **Phase 4: Final Workshop (26 – 27 Febbraio 2026 in Bari)** Teams will present and discuss their work during the dedicated ATE-IT workshop at EVALITA.

## What are the rules

There are no restrictions on the techniques that can be used: supervised and unsupervised machine learning, rule-based systems, deep learning, prompting, etc. However, we discourage the mere fine-tuning of the latest models. Conversely, we strongly encourage the development of techniques that can provide insights into ATE and terminology, thus contributing to advancing our field of study. In particular, we encourage the use of **open-source LLM** and the exploitation of **linguistic knowledge**.

The only external resources allowed are: pretrained embeddings, LLMs, and other pretrained models. External corpora or lexical resources are **NOT allowed**. The resources used must be clearly documented in the technical report.

Teams can participate in Subtask A (Term Extraction) only, or in both subtasks. It is not allowed to participate only in Subtask B (Term Variants Clustering).

Each team can submit up to **2 runs per subtask**. The best run (per evaluation metric) will be considered for ranking. 

Manual annotation of the test data is strictly forbidden. Any evidence of test-set leakage will result in disqualification.

